2024-05-12 14:16:37,987 | INFO | 
model:
  name: DNN5
  architecture:
    in_channels: 784
    out_channels: 10
    activation: CosSinLU
optimizer:
  name: Adam
  parameters:
    lr: 0.0003
    weight_decay: 1e-05
scheduler:
  num: 1
  scheduler0:
    name: ExponentialLR
    parameters:
      gamma: 0.5
dataset:
  name: MNIST
  batch_size: 32
  split:
    train: 0.9
    valid: 0.1
    test: 1.0
train:
  epochs: 10
  device: cuda:0
  save_path: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
  save_every: 2
test:
  device: cuda:0
  checkpoint: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
2024-05-12 14:16:37,987 | INFO | 
DNN(
  (first_fc): Linear(in_features=784, out_features=512, bias=True)
  (first_act): CosSinLU()
  (layers): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): CosSinLU()
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): CosSinLU()
    (4): Linear(in_features=128, out_features=64, bias=True)
    (5): CosSinLU()
  )
  (last_fc): Linear(in_features=64, out_features=10, bias=True)
)
2024-05-12 14:16:37,987 | INFO | 
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 1e-05
)
2024-05-12 14:16:37,987 | INFO | 
ExponentialLR (
  gamma: 0.5
  base_lrs: [0.0003]
  last_epoch: 0
  verbose: False
  _step_count: 1
  _get_lr_called_within_step: False
  _last_lr: [0.0003]
)
2024-05-12 14:16:37,987 | INFO | 
CrossEntropyLoss()
2024-05-12 14:16:48,893 | INFO | cuda:0 epoch: 1/10 train_loss: 0.5725 valid_loss: 0.3251 epoch_time: 10.862 sec
2024-05-12 14:16:59,457 | INFO | cuda:0 epoch: 2/10 train_loss: 0.2412 valid_loss: 0.2267 epoch_time: 10.564 sec
2024-05-12 14:17:09,221 | INFO | cuda:0 epoch: 3/10 train_loss: 0.1922 valid_loss: 0.1898 epoch_time: 9.764 sec
2024-05-12 14:17:18,875 | INFO | cuda:0 epoch: 4/10 train_loss: 0.1609 valid_loss: 0.1859 epoch_time: 9.654 sec
2024-05-12 14:17:28,466 | INFO | cuda:0 epoch: 5/10 train_loss: 0.1480 valid_loss: 0.1652 epoch_time: 9.591 sec
2024-05-12 14:17:38,062 | INFO | cuda:0 epoch: 6/10 train_loss: 0.1447 valid_loss: 0.1615 epoch_time: 9.595 sec
2024-05-12 14:17:47,666 | INFO | cuda:0 epoch: 7/10 train_loss: 0.1417 valid_loss: 0.1562 epoch_time: 9.604 sec
2024-05-12 14:17:57,201 | INFO | cuda:0 epoch: 8/10 train_loss: 0.1420 valid_loss: 0.1611 epoch_time: 9.535 sec
2024-05-12 14:18:06,777 | INFO | cuda:0 epoch: 9/10 train_loss: 0.1377 valid_loss: 0.1571 epoch_time: 9.576 sec
2024-05-12 14:18:16,383 | INFO | cuda:0 epoch: 10/10 train_loss: 0.1374 valid_loss: 0.1553 epoch_time: 9.607 sec
2024-05-12 14:18:24,696 | INFO | 
train_accuracy: 0.957 train_precision: 0.968 train_recall: 0.957 train_f1: 0.958 valid_accuracy: 0.952 valid_precision: 0.964 valid_recall: 0.952 valid_f1: 0.952 total_time: 98.353 sec
2024-05-12 14:53:28,991 | INFO | 
model:
  name: DNN5
  architecture:
    in_channels: 784
    out_channels: 10
    activation: CosSinLU
optimizer:
  name: Adam
  parameters:
    lr: 0.0003
    weight_decay: 1e-05
scheduler:
  num: 1
  scheduler0:
    name: ExponentialLR
    parameters:
      gamma: 0.5
dataset:
  name: MNIST
  batch_size: 32
  split:
    train: 0.9
    valid: 0.1
    test: 1.0
train:
  epochs: 10
  device: cuda:0
  save_path: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
  save_every: 2
test:
  device: cuda:0
  checkpoint: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
2024-05-12 14:53:28,991 | INFO | 
DNN(
  (first_fc): Linear(in_features=784, out_features=512, bias=True)
  (first_act): CosSinLU()
  (layers): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): CosSinLU()
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): CosSinLU()
    (4): Linear(in_features=128, out_features=64, bias=True)
    (5): CosSinLU()
  )
  (last_fc): Linear(in_features=64, out_features=10, bias=True)
)
2024-05-12 14:53:28,991 | INFO | 
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 1e-05
)
2024-05-12 14:53:28,991 | INFO | 
ExponentialLR (
  gamma: 0.5
  base_lrs: [0.0003]
  last_epoch: 0
  verbose: False
  _step_count: 1
  _get_lr_called_within_step: False
  _last_lr: [0.0003]
)
2024-05-12 14:53:28,991 | INFO | 
CrossEntropyLoss()
2024-05-12 14:53:38,581 | INFO | cuda:0 epoch: 1/10 train_loss: 0.6566 valid_loss: 0.3687 epoch_time: 9.558 sec
2024-05-12 14:53:48,285 | INFO | cuda:0 epoch: 2/10 train_loss: 0.2799 valid_loss: 0.2760 epoch_time: 9.704 sec
2024-05-12 14:53:58,035 | INFO | cuda:0 epoch: 3/10 train_loss: 0.2227 valid_loss: 0.2194 epoch_time: 9.750 sec
2024-05-12 14:54:07,678 | INFO | cuda:0 epoch: 4/10 train_loss: 0.1894 valid_loss: 0.2100 epoch_time: 9.643 sec
2024-05-12 14:54:17,324 | INFO | cuda:0 epoch: 5/10 train_loss: 0.1736 valid_loss: 0.1928 epoch_time: 9.646 sec
2024-05-12 14:54:27,079 | INFO | cuda:0 epoch: 6/10 train_loss: 0.1700 valid_loss: 0.1837 epoch_time: 9.754 sec
2024-05-12 14:54:36,767 | INFO | cuda:0 epoch: 7/10 train_loss: 0.1652 valid_loss: 0.1907 epoch_time: 9.688 sec
2024-05-12 14:54:46,517 | INFO | cuda:0 epoch: 8/10 train_loss: 0.1639 valid_loss: 0.1859 epoch_time: 9.750 sec
2024-05-12 14:54:56,240 | INFO | cuda:0 epoch: 9/10 train_loss: 0.1614 valid_loss: 0.1765 epoch_time: 9.723 sec
2024-05-12 14:55:06,282 | INFO | cuda:0 epoch: 10/10 train_loss: 0.1601 valid_loss: 0.1741 epoch_time: 10.042 sec
2024-05-12 14:55:14,763 | INFO | 
train_accuracy: 0.951 train_precision: 0.963 train_recall: 0.951 train_f1: 0.951 valid_accuracy: 0.947 valid_precision: 0.960 valid_recall: 0.947 valid_f1: 0.947 total_time: 97.260 sec
2024-05-12 15:09:19,890 | INFO | 
model:
  name: DNN5
  architecture:
    in_channels: 784
    out_channels: 10
    activation: CosSinLU
optimizer:
  name: Adam
  parameters:
    lr: 0.0003
    weight_decay: 1e-05
scheduler:
  num: 1
  scheduler0:
    name: ExponentialLR
    parameters:
      gamma: 0.5
dataset:
  name: MNIST
  batch_size: 32
  split:
    train: 0.9
    valid: 0.1
    test: 1.0
train:
  epochs: 10
  device: cuda:0
  save_path: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
  save_every: 2
test:
  device: cuda:0
  checkpoint: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
2024-05-12 15:09:19,890 | INFO | 
DNN(
  (first_fc): Linear(in_features=784, out_features=512, bias=True)
  (first_act): CosSinLU()
  (layers): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): CosSinLU()
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): CosSinLU()
    (4): Linear(in_features=128, out_features=64, bias=True)
    (5): CosSinLU()
  )
  (last_fc): Linear(in_features=64, out_features=10, bias=True)
)
2024-05-12 15:09:19,890 | INFO | 
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 1e-05
)
2024-05-12 15:09:19,890 | INFO | 
ExponentialLR (
  gamma: 0.5
  base_lrs: [0.0003]
  last_epoch: 0
  verbose: False
  _step_count: 1
  _get_lr_called_within_step: False
  _last_lr: [0.0003]
)
2024-05-12 15:09:19,890 | INFO | 
CrossEntropyLoss()
2024-05-12 15:09:32,035 | INFO | cuda:0 epoch: 1/10 train_loss: 0.5351 valid_loss: 0.2863 epoch_time: 12.080 sec
2024-05-12 15:09:43,077 | INFO | cuda:0 epoch: 2/10 train_loss: 0.2256 valid_loss: 0.2196 epoch_time: 11.042 sec
2024-05-12 15:09:54,174 | INFO | cuda:0 epoch: 3/10 train_loss: 0.1764 valid_loss: 0.1783 epoch_time: 11.097 sec
2024-05-12 15:10:04,615 | INFO | cuda:0 epoch: 4/10 train_loss: 0.1501 valid_loss: 0.1724 epoch_time: 10.441 sec
2024-05-12 15:10:15,927 | INFO | cuda:0 epoch: 5/10 train_loss: 0.1376 valid_loss: 0.1576 epoch_time: 11.311 sec
2024-05-12 15:10:26,126 | INFO | cuda:0 epoch: 6/10 train_loss: 0.1339 valid_loss: 0.1502 epoch_time: 10.199 sec
2024-05-12 15:10:36,787 | INFO | cuda:0 epoch: 7/10 train_loss: 0.1321 valid_loss: 0.1498 epoch_time: 10.661 sec
2024-05-12 15:10:47,821 | INFO | cuda:0 epoch: 8/10 train_loss: 0.1292 valid_loss: 0.1515 epoch_time: 11.034 sec
2024-05-12 15:10:58,251 | INFO | cuda:0 epoch: 9/10 train_loss: 0.1277 valid_loss: 0.1422 epoch_time: 10.430 sec
2024-05-12 15:11:08,565 | INFO | cuda:0 epoch: 10/10 train_loss: 0.1262 valid_loss: 0.1472 epoch_time: 10.314 sec
2024-05-12 15:11:17,153 | INFO | 
train_accuracy: 0.961 train_precision: 0.970 train_recall: 0.961 train_f1: 0.961 valid_accuracy: 0.957 valid_precision: 0.967 valid_recall: 0.957 valid_f1: 0.957 total_time: 108.610 sec
2024-05-12 15:13:15,381 | INFO | 
model:
  name: DNN5
  architecture:
    in_channels: 784
    out_channels: 10
    activation: CosSinLU
optimizer:
  name: Adam
  parameters:
    lr: 0.0003
    weight_decay: 1e-05
scheduler:
  num: 1
  scheduler0:
    name: ExponentialLR
    parameters:
      gamma: 0.5
dataset:
  name: MNIST
  batch_size: 32
  split:
    train: 0.9
    valid: 0.1
    test: 1.0
train:
  epochs: 10
  device: cuda:0
  save_path: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
  save_every: 2
test:
  device: cuda:0
  checkpoint: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
2024-05-12 15:13:15,382 | INFO | 
DNN(
  (first_fc): Linear(in_features=784, out_features=512, bias=True)
  (first_act): CosSinLU()
  (layers): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): CosSinLU()
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): CosSinLU()
    (4): Linear(in_features=128, out_features=64, bias=True)
    (5): CosSinLU()
  )
  (last_fc): Linear(in_features=64, out_features=10, bias=True)
)
2024-05-12 15:13:15,382 | INFO | 
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 1e-05
)
2024-05-12 15:13:15,382 | INFO | 
ExponentialLR (
  gamma: 0.5
  base_lrs: [0.0003]
  last_epoch: 0
  verbose: False
  _step_count: 1
  _get_lr_called_within_step: False
  _last_lr: [0.0003]
)
2024-05-12 15:13:15,382 | INFO | 
CrossEntropyLoss()
2024-05-12 15:13:25,983 | INFO | cuda:0 epoch: 1/10 train_loss: 0.5197 valid_loss: 0.2883 epoch_time: 10.541 sec
2024-05-12 15:13:36,392 | INFO | cuda:0 epoch: 2/10 train_loss: 0.2183 valid_loss: 0.2125 epoch_time: 10.409 sec
2024-05-12 15:13:46,553 | INFO | cuda:0 epoch: 3/10 train_loss: 0.1715 valid_loss: 0.1758 epoch_time: 10.161 sec
2024-05-12 15:13:56,804 | INFO | cuda:0 epoch: 4/10 train_loss: 0.1455 valid_loss: 0.1656 epoch_time: 10.250 sec
2024-05-12 15:14:07,006 | INFO | cuda:0 epoch: 5/10 train_loss: 0.1325 valid_loss: 0.1520 epoch_time: 10.202 sec
2024-05-12 15:14:17,322 | INFO | cuda:0 epoch: 6/10 train_loss: 0.1289 valid_loss: 0.1433 epoch_time: 10.316 sec
2024-05-12 15:14:27,565 | INFO | cuda:0 epoch: 7/10 train_loss: 0.1265 valid_loss: 0.1427 epoch_time: 10.243 sec
2024-05-12 15:14:39,173 | INFO | cuda:0 epoch: 8/10 train_loss: 0.1241 valid_loss: 0.1438 epoch_time: 11.608 sec
2024-05-12 15:14:50,032 | INFO | cuda:0 epoch: 9/10 train_loss: 0.1232 valid_loss: 0.1339 epoch_time: 10.858 sec
2024-05-12 15:15:00,331 | INFO | cuda:0 epoch: 10/10 train_loss: 0.1223 valid_loss: 0.1400 epoch_time: 10.299 sec
2024-05-12 15:15:09,321 | INFO | 
train_accuracy: 0.962 train_precision: 0.971 train_recall: 0.962 train_f1: 0.962 valid_accuracy: 0.957 valid_precision: 0.968 valid_recall: 0.957 valid_f1: 0.957 total_time: 104.890 sec
2024-05-12 15:16:37,805 | INFO | 
model:
  name: DNN5
  architecture:
    in_channels: 784
    out_channels: 10
    activation: CosSinLU
optimizer:
  name: Adam
  parameters:
    lr: 0.0003
    weight_decay: 1e-05
scheduler:
  num: 1
  scheduler0:
    name: ExponentialLR
    parameters:
      gamma: 0.5
dataset:
  name: MNIST
  batch_size: 32
  split:
    train: 0.9
    valid: 0.1
    test: 1.0
train:
  epochs: 10
  device: cuda:0
  save_path: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
  save_every: 2
test:
  device: cuda:0
  checkpoint: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
2024-05-12 15:16:37,806 | INFO | 
DNN(
  (first_fc): Linear(in_features=784, out_features=512, bias=True)
  (first_act): CosSinLU()
  (layers): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): CosSinLU()
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): CosSinLU()
    (4): Linear(in_features=128, out_features=64, bias=True)
    (5): CosSinLU()
  )
  (last_fc): Linear(in_features=64, out_features=10, bias=True)
)
2024-05-12 15:16:37,806 | INFO | 
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 1e-05
)
2024-05-12 15:16:37,806 | INFO | 
ExponentialLR (
  gamma: 0.5
  base_lrs: [0.0003]
  last_epoch: 0
  verbose: False
  _step_count: 1
  _get_lr_called_within_step: False
  _last_lr: [0.0003]
)
2024-05-12 15:16:37,806 | INFO | 
CrossEntropyLoss()
2024-05-12 15:16:48,259 | INFO | cuda:0 epoch: 1/10 train_loss: 0.5131 valid_loss: 0.2842 epoch_time: 10.412 sec
2024-05-12 15:16:58,719 | INFO | cuda:0 epoch: 2/10 train_loss: 0.2146 valid_loss: 0.2056 epoch_time: 10.460 sec
2024-05-12 15:17:09,097 | INFO | cuda:0 epoch: 3/10 train_loss: 0.1688 valid_loss: 0.1713 epoch_time: 10.378 sec
2024-05-12 15:17:19,435 | INFO | cuda:0 epoch: 4/10 train_loss: 0.1432 valid_loss: 0.1615 epoch_time: 10.339 sec
2024-05-12 15:17:29,820 | INFO | cuda:0 epoch: 5/10 train_loss: 0.1300 valid_loss: 0.1493 epoch_time: 10.384 sec
2024-05-12 15:17:40,202 | INFO | cuda:0 epoch: 6/10 train_loss: 0.1258 valid_loss: 0.1401 epoch_time: 10.381 sec
2024-05-12 15:17:50,578 | INFO | cuda:0 epoch: 7/10 train_loss: 0.1240 valid_loss: 0.1406 epoch_time: 10.376 sec
2024-05-12 15:18:00,918 | INFO | cuda:0 epoch: 8/10 train_loss: 0.1212 valid_loss: 0.1407 epoch_time: 10.339 sec
2024-05-12 15:18:11,243 | INFO | cuda:0 epoch: 9/10 train_loss: 0.1205 valid_loss: 0.1298 epoch_time: 10.325 sec
2024-05-12 15:18:21,646 | INFO | cuda:0 epoch: 10/10 train_loss: 0.1200 valid_loss: 0.1358 epoch_time: 10.403 sec
2024-05-12 15:18:30,351 | INFO | 
train_accuracy: 0.963 train_precision: 0.972 train_recall: 0.963 train_f1: 0.963 valid_accuracy: 0.960 valid_precision: 0.970 valid_recall: 0.960 valid_f1: 0.960 total_time: 103.799 sec
2024-05-12 15:19:33,643 | INFO | 
model:
  name: DNN5
  architecture:
    in_channels: 784
    out_channels: 10
    activation: CosSinLU
optimizer:
  name: Adam
  parameters:
    lr: 0.0003
    weight_decay: 1e-05
scheduler:
  num: 1
  scheduler0:
    name: ExponentialLR
    parameters:
      gamma: 0.5
dataset:
  name: MNIST
  batch_size: 32
  split:
    train: 0.9
    valid: 0.1
    test: 1.0
train:
  epochs: 10
  device: cuda:0
  save_path: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
  save_every: 2
test:
  device: cuda:0
  checkpoint: ./checkpoints/cossinlu/mnist/
  log_path: ./logs/cossinlu/mnist/
  seed: 42
2024-05-12 15:19:33,643 | INFO | 
DNN(
  (first_fc): Linear(in_features=784, out_features=512, bias=True)
  (first_act): CosSinLU()
  (layers): Sequential(
    (0): Linear(in_features=512, out_features=256, bias=True)
    (1): CosSinLU()
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): CosSinLU()
    (4): Linear(in_features=128, out_features=64, bias=True)
    (5): CosSinLU()
  )
  (last_fc): Linear(in_features=64, out_features=10, bias=True)
)
2024-05-12 15:19:33,643 | INFO | 
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    initial_lr: 0.0003
    lr: 0.0003
    maximize: False
    weight_decay: 1e-05
)
2024-05-12 15:19:33,643 | INFO | 
ExponentialLR (
  gamma: 0.5
  base_lrs: [0.0003]
  last_epoch: 0
  verbose: False
  _step_count: 1
  _get_lr_called_within_step: False
  _last_lr: [0.0003]
)
2024-05-12 15:19:33,643 | INFO | 
CrossEntropyLoss()
2024-05-12 15:19:44,496 | INFO | cuda:0 epoch: 1/10 train_loss: 0.5103 valid_loss: 0.2848 epoch_time: 10.812 sec
2024-05-12 15:19:55,173 | INFO | cuda:0 epoch: 2/10 train_loss: 0.2120 valid_loss: 0.2036 epoch_time: 10.677 sec
2024-05-12 15:20:05,876 | INFO | cuda:0 epoch: 3/10 train_loss: 0.1663 valid_loss: 0.1697 epoch_time: 10.702 sec
2024-05-12 15:20:16,075 | INFO | cuda:0 epoch: 4/10 train_loss: 0.1411 valid_loss: 0.1581 epoch_time: 10.199 sec
2024-05-12 15:20:29,101 | INFO | cuda:0 epoch: 5/10 train_loss: 0.1281 valid_loss: 0.1482 epoch_time: 13.026 sec
2024-05-12 15:20:39,477 | INFO | cuda:0 epoch: 6/10 train_loss: 0.1236 valid_loss: 0.1388 epoch_time: 10.376 sec
2024-05-12 15:20:49,654 | INFO | cuda:0 epoch: 7/10 train_loss: 0.1219 valid_loss: 0.1399 epoch_time: 10.177 sec
2024-05-12 15:20:59,155 | INFO | cuda:0 epoch: 8/10 train_loss: 0.1185 valid_loss: 0.1397 epoch_time: 9.500 sec
2024-05-12 15:21:08,812 | INFO | cuda:0 epoch: 9/10 train_loss: 0.1184 valid_loss: 0.1285 epoch_time: 9.657 sec
2024-05-12 15:21:18,454 | INFO | cuda:0 epoch: 10/10 train_loss: 0.1181 valid_loss: 0.1331 epoch_time: 9.642 sec
2024-05-12 15:21:27,058 | INFO | 
train_accuracy: 0.964 train_precision: 0.973 train_recall: 0.964 train_f1: 0.964 valid_accuracy: 0.961 valid_precision: 0.971 valid_recall: 0.961 valid_f1: 0.961 total_time: 104.769 sec
